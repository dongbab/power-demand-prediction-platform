import asyncio
import uvicorn
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.responses import HTMLResponse, JSONResponse
from contextlib import asynccontextmanager
from datetime import datetime, timedelta
import logging
import os
import pandas as pd
from functools import lru_cache
from typing import Dict, Any, List, Optional

from prediction.predictor import RealTimePowerPredictor
from prediction.scheduler import PredictionScheduler
from utils.config import PredictionConfig, ConfigManager
from utils.logger import setup_logger
from data.loader import ChargingDataLoader

# ì „ì—­ ë³€ìˆ˜
predictor = None
scheduler = None
logger = None

# ìºì‹œ ì„¤ì •
CACHE_EXPIRE_MINUTES = 10
_stations_cache = None
_cache_timestamp = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬"""
    global predictor, scheduler, logger
    
    config = ConfigManager().config
    logger = setup_logger("main", "logs/main.log")
    
    predictor = RealTimePowerPredictor("DEFAULT_STATION")
    scheduler = PredictionScheduler()
    
    logger.info("100kW ê¸‰ì†ì¶©ì „ì†Œ ì „ë ¥ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì‹œì‘")
    scheduler.start_scheduled_jobs()
    
    yield
    
    if scheduler:
        scheduler.stop()
    logger.info("ì‹œìŠ¤í…œ ì¢…ë£Œ")


# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="100kW ê¸‰ì†ì¶©ì „ì†Œ ì „ë ¥ ì˜ˆì¸¡ API",
    description="CSV ë°ì´í„° ê¸°ë°˜ ì „ë ¥ ìˆ˜ìš” ì˜ˆì¸¡ ë° ê³„ì•½ ìµœì í™” ì‹œìŠ¤í…œ",
    version="2.2.0",
    docs_url="/api/docs",
    redoc_url="/api/redoc",
    lifespan=lifespan
)

# ì •ì  íŒŒì¼ ë° í…œí”Œë¦¿ ì„¤ì •
if os.path.exists("static"):
    app.mount("/static", StaticFiles(directory="static"), name="static")

if os.path.exists("templates"):
    templates = Jinja2Templates(directory="templates")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# === í•µì‹¬ ë°ì´í„° ë¡œì§ ===
def extract_stations_from_csv() -> Dict[str, Dict[str, Any]]:
    """CSVì—ì„œ ì¶©ì „ì†Œ ì •ë³´ ì¶”ì¶œ"""
    try:
        logger.info("CSVì—ì„œ ì¶©ì „ì†Œ ì •ë³´ ì¶”ì¶œ ì‹œì‘...")
        
        # ì „ì²´ ë°ì´í„° ë¡œë“œ
        loader = ChargingDataLoader("ALL")
        df = loader.load_historical_sessions(90)  # 3ê°œì›” ë°ì´í„°
        
        if df.empty:
            logger.warning("CSV ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return {}
        
        stations = {}
        
        # ì¶©ì „ì†ŒIDë³„ë¡œ ê·¸ë£¹í™”
        if 'ì¶©ì „ì†ŒID' in df.columns:
            station_ids = df['ì¶©ì „ì†ŒID'].unique()
            logger.info(f"ë°œê²¬ëœ ì¶©ì „ì†Œ: {len(station_ids)}ê°œ")
            
            for station_id in station_ids:
                station_df = df[df['ì¶©ì „ì†ŒID'] == station_id]
                
                # ê¸°ë³¸ ì •ë³´
                station_info = {
                    "id": station_id,
                    "name": extract_station_name(station_df),
                    "location": extract_station_location(station_df),
                    "charger_type": extract_charger_type(station_df),
                    "connector_type": extract_connector_type(station_df),
                    "region": extract_region(station_df),
                    "city": extract_city(station_df),
                    "status": determine_station_status(station_df),
                    "data_sessions": len(station_df),
                    "date_range": get_date_range(station_df),
                    "last_activity": get_last_activity(station_df)
                }
                
                stations[station_id] = station_info
            
            # ì „ì²´ ë¶„ì„ ì˜µì…˜ ì¶”ê°€
            if stations:
                stations["ALL"] = {
                    "id": "ALL",
                    "name": "ì „ì²´ ì¶©ì „ì†Œ í†µí•© ë¶„ì„",
                    "location": f"ì „êµ­ ({len(station_ids)}ê°œ ì¶©ì „ì†Œ)",
                    "charger_type": "100kW ê¸‰ì†ì¶©ì „ê¸°",
                    "connector_type": "DCì½¤ë³´",
                    "region": "ì „êµ­",
                    "city": "ì „ì²´",
                    "status": "ì •ìƒ ìš´ì˜",
                    "data_sessions": len(df),
                    "date_range": get_date_range(df),
                    "last_activity": get_last_activity(df)
                }
        
        logger.info(f"âœ… {len(stations)}ê°œ ì¶©ì „ì†Œ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ")
        return stations
        
    except Exception as e:
        logger.error(f"CSV ì¶©ì „ì†Œ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return {}


# ë°ì´í„° ì¶”ì¶œ í—¬í¼ í•¨ìˆ˜ë“¤
def extract_station_name(station_df: pd.DataFrame) -> str:
    """ì¶©ì „ì†Œëª… ì¶”ì¶œ"""
    if 'ì¶©ì „ì†Œëª…' in station_df.columns and not station_df['ì¶©ì „ì†Œëª…'].empty:
        return station_df['ì¶©ì „ì†Œëª…'].iloc[0]
    
    station_id = station_df['ì¶©ì „ì†ŒID'].iloc[0] if 'ì¶©ì „ì†ŒID' in station_df.columns else "Unknown"
    return f"ì¶©ì „ì†Œ {station_id}"


def extract_station_location(station_df: pd.DataFrame) -> str:
    """ì¶©ì „ì†Œ ì£¼ì†Œ ì¶”ì¶œ"""
    if 'ì¶©ì „ì†Œì£¼ì†Œ' in station_df.columns and not station_df['ì¶©ì „ì†Œì£¼ì†Œ'].empty:
        return station_df['ì¶©ì „ì†Œì£¼ì†Œ'].iloc[0]
    return "ì£¼ì†Œ ì •ë³´ ì—†ìŒ"


def extract_charger_type(station_df: pd.DataFrame) -> str:
    """ì¶©ì „ê¸° íƒ€ì… ì¶”ì¶œ"""
    if 'ì¶©ì „ê¸° êµ¬ë¶„' in station_df.columns and not station_df['ì¶©ì „ê¸° êµ¬ë¶„'].empty:
        charger_type = station_df['ì¶©ì „ê¸° êµ¬ë¶„'].iloc[0]
        return f"{charger_type}"
    return "100kW ê¸‰ì†ì¶©ì „ê¸°"


def extract_connector_type(station_df: pd.DataFrame) -> str:
    """ì»¤ë„¥í„° íƒ€ì… ì¶”ì¶œ"""
    if 'ì»¤ë„¥í„°ëª…' in station_df.columns and not station_df['ì»¤ë„¥í„°ëª…'].empty:
        return station_df['ì»¤ë„¥í„°ëª…'].iloc[0]
    return "DCì½¤ë³´"


def extract_region(station_df: pd.DataFrame) -> str:
    """ì§€ì—­ ì •ë³´ ì¶”ì¶œ"""
    location = extract_station_location(station_df)
    if location and location != "ì£¼ì†Œ ì •ë³´ ì—†ìŒ":
        parts = location.split()
        if parts:
            return parts[0]  # ì²« ë²ˆì§¸ ë¶€ë¶„ (ì˜ˆ: ì„œìš¸ì‹œ, ê²½ê¸°ë„)
    return "ë¯¸ìƒ"


def extract_city(station_df: pd.DataFrame) -> str:
    """ë„ì‹œ ì •ë³´ ì¶”ì¶œ"""
    location = extract_station_location(station_df)
    if location and location != "ì£¼ì†Œ ì •ë³´ ì—†ìŒ":
        parts = location.split()
        if len(parts) >= 2:
            return parts[1]  # ë‘ ë²ˆì§¸ ë¶€ë¶„ (ì˜ˆ: ê°•ë‚¨êµ¬, ìˆ˜ì›ì‹œ)
    return "ë¯¸ìƒ"


def determine_station_status(station_df: pd.DataFrame) -> str:
    """ì¶©ì „ì†Œ ìƒíƒœ íŒë‹¨"""
    if 'ì¶©ì „ì‹œì‘ì¼ì‹œ' not in station_df.columns:
        return "ìƒíƒœ ë¶ˆëª…"
    
    try:
        latest_session = station_df['ì¶©ì „ì‹œì‘ì¼ì‹œ'].max()
        if pd.isna(latest_session):
            return "ìƒíƒœ ë¶ˆëª…"
        
        days_ago = (datetime.now() - latest_session).days
        
        if days_ago <= 7:
            return "ì •ìƒ ìš´ì˜"
        elif days_ago <= 30:
            return "ì£¼ì˜ í•„ìš”"
        else:
            return "ì ê²€ í•„ìš”"
            
    except Exception:
        return "ìƒíƒœ ë¶ˆëª…"


def get_date_range(df: pd.DataFrame) -> Dict[str, Optional[str]]:
    """ë°ì´í„° ë‚ ì§œ ë²”ìœ„"""
    if 'ì¶©ì „ì‹œì‘ì¼ì‹œ' not in df.columns:
        return {"start": None, "end": None}
    
    try:
        start_date = df['ì¶©ì „ì‹œì‘ì¼ì‹œ'].min()
        end_date = df['ì¶©ì „ì‹œì‘ì¼ì‹œ'].max()
        
        return {
            "start": start_date.isoformat() if pd.notna(start_date) else None,
            "end": end_date.isoformat() if pd.notna(end_date) else None
        }
    except Exception:
        return {"start": None, "end": None}


def get_last_activity(df: pd.DataFrame) -> Optional[str]:
    """ë§ˆì§€ë§‰ í™œë™ ì¼ì‹œ"""
    if 'ì¶©ì „ì‹œì‘ì¼ì‹œ' not in df.columns:
        return None
    
    try:
        latest = df['ì¶©ì „ì‹œì‘ì¼ì‹œ'].max()
        return latest.isoformat() if pd.notna(latest) else None
    except Exception:
        return None


# ìºì‹± ë¡œì§
def get_stations_with_cache() -> Dict[str, Dict[str, Any]]:
    """ìºì‹œë¥¼ í™œìš©í•œ ì¶©ì „ì†Œ ì •ë³´ ì¡°íšŒ"""
    global _stations_cache, _cache_timestamp
    
    # ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬
    if (_stations_cache is not None and _cache_timestamp is not None and 
        datetime.now() - _cache_timestamp < timedelta(minutes=CACHE_EXPIRE_MINUTES)):
        logger.debug("ìºì‹œëœ ì¶©ì „ì†Œ ì •ë³´ ì‚¬ìš©")
        return _stations_cache
    
    # ìƒˆë¡œ ë¡œë“œ
    logger.info("ìƒˆë¡œìš´ ì¶©ì „ì†Œ ì •ë³´ ë¡œë”©...")
    stations = extract_stations_from_csv()
    
    # ìºì‹œ ì—…ë°ì´íŠ¸
    _stations_cache = stations
    _cache_timestamp = datetime.now()
    
    return stations


def invalidate_cache():
    """ìºì‹œ ë¬´íš¨í™”"""
    global _stations_cache, _cache_timestamp
    _stations_cache = None
    _cache_timestamp = None
    logger.info("ì¶©ì „ì†Œ ìºì‹œ ë¬´íš¨í™”")


# === ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ ===
@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        stations = get_stations_with_cache()
        active_stations = len([s for s in stations.values() if s["status"] == "ì •ìƒ ìš´ì˜"])
        total_sessions = sum(s.get("data_sessions", 0) for s in stations.values() if s["id"] != "ALL")
        
        return {
            "message": "âš¡ 100kW ê¸‰ì†ì¶©ì „ì†Œ ì „ë ¥ ì˜ˆì¸¡ ì‹œìŠ¤í…œ",
            "version": "2.2.0",
            "status": "running",
            "data_driven": True,
            "stations": {
                "total": len(stations) - 1 if "ALL" in stations else len(stations),
                "active": active_stations - 1 if "ALL" in stations else active_stations,
                "total_sessions": total_sessions
            },
            "features": [
                "CSV ë°ì´í„° ê¸°ë°˜ ë¶„ì„",
                "ì‹¤ì‹œê°„ ì „ë ¥ ì˜ˆì¸¡", 
                "ì›”ë³„ ê³„ì•½ ê¶Œê³ ",
                "ì‹œê°í™” ëŒ€ì‹œë³´ë“œ",
                "ë™ì  ì¶©ì „ì†Œ ê´€ë¦¬"
            ],
            "endpoints": {
                "station_selector": "/station-selector",
                "dashboard": "/dashboard/{station_id}",
                "api_docs": "/api/docs",
                "stations_list": "/api/stations",
                "predict": "/predict/{station_id}",
                "analysis": "/api/station-analysis/{station_id}"
            },
            "cache_info": {
                "enabled": True,
                "expire_minutes": CACHE_EXPIRE_MINUTES,
                "last_updated": _cache_timestamp.isoformat() if _cache_timestamp else None
            }
        }
    except Exception as e:
        logger.error(f"ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ ì˜¤ë¥˜: {e}")
        return {"error": "ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘", "message": str(e)}


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    try:
        stations = get_stations_with_cache()
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "stations_loaded": len(stations),
            "cache_active": _stations_cache is not None,
            "csv_accessible": True
        }
    except Exception as e:
        return {
            "status": "degraded",
            "timestamp": datetime.now().isoformat(),
            "error": str(e)
        }


# === í˜ì´ì§€ ë¼ìš°íŠ¸ ===
@app.get("/station-selector", response_class=HTMLResponse)
async def station_selector(request: Request):
    """ì¶©ì „ì†Œ ì„ íƒ í˜ì´ì§€"""
    try:
        stations = get_stations_with_cache()
        
        if not stations:
            raise HTTPException(status_code=503, detail="ì¶©ì „ì†Œ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CSV íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        if 'templates' in globals():
            return templates.TemplateResponse("station_selector.html", {
                "request": request,
                "stations": stations,
                "total_stations": len(stations)
            })
        else:
            raise HTTPException(status_code=404, detail="í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"station-selector í˜ì´ì§€ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")


@app.get("/dashboard/{station_id}", response_class=HTMLResponse)
async def dashboard(request: Request, station_id: str):
    """ì¶©ì „ì†Œë³„ ëŒ€ì‹œë³´ë“œ"""
    try:
        stations = get_stations_with_cache()
        
        if station_id not in stations:
            available_ids = list(stations.keys())
            raise HTTPException(
                status_code=404, 
                detail=f"ì¶©ì „ì†Œ '{station_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ID: {available_ids}"
            )
        
        station_info = stations[station_id]
        
        if 'templates' in globals():
            return templates.TemplateResponse("dashboard.html", {
                "request": request,
                "station_id": station_id,
                "station_info": station_info
            })
        else:
            raise HTTPException(status_code=404, detail="í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ëŒ€ì‹œë³´ë“œ í˜ì´ì§€ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ëŒ€ì‹œë³´ë“œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")


# === API ì—”ë“œí¬ì¸íŠ¸ ===
@app.get("/api/stations")
async def list_stations():
    """ì¶©ì „ì†Œ ëª©ë¡ API"""
    try:
        stations = get_stations_with_cache()
        
        stations_list = []
        for station_id, station in stations.items():
            if station_id == "ALL":
                continue
            
            # ê°„ë‹¨í•œ ì´ìš©ë¥  ê³„ì‚°
            try:
                loader = ChargingDataLoader(station_id)
                summary = loader.get_data_summary()
                utilization = "N/A"
                if 'power_stats' in summary and summary['power_stats']:
                    utilization = round((summary['power_stats']['mean'] / 100) * 100, 1)
            except:
                utilization = "N/A"
            
            stations_list.append({
                "id": station_id,
                "name": station["name"],
                "location": station["location"],
                "charger_type": station["charger_type"],
                "connector_type": station["connector_type"],
                "status": station["status"],
                "region": station["region"],
                "city": station["city"],
                "data_sessions": station["data_sessions"],
                "utilization": f"{utilization}%" if utilization != "N/A" else "N/A",
                "last_activity": station["last_activity"]
            })
        
        return {
            "stations": stations_list,
            "total": len(stations_list),
            "active": len([s for s in stations_list if s["status"] == "ì •ìƒ ìš´ì˜"]),
            "regions": list(set(s["region"] for s in stations_list)),
            "last_updated": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì¶©ì „ì†Œ ëª©ë¡ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/predict/{station_id}")
async def predict_peak_power(station_id: str):
    """ì‹¤ì‹œê°„ ì „ë ¥ ì˜ˆì¸¡"""
    try:
        stations = get_stations_with_cache()
        
        if station_id not in stations:
            raise HTTPException(status_code=404, detail=f"ì¶©ì „ì†Œ '{station_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        station_predictor = RealTimePowerPredictor(station_id)
        result = await station_predictor.predict_next_hour_peak()
        
        if result is None:
            # ê¸°ë³¸ ì˜ˆì¸¡ê°’ ìƒì„±
            loader = ChargingDataLoader(station_id)
            patterns = loader.analyze_charging_patterns()
            
            predicted_peak = 45.0
            if 'power_statistics' in patterns:
                stats = patterns['power_statistics']
                predicted_peak = min(stats.get('percentile_95', 50), 95)
            
            result = {
                "station_id": station_id,
                "station_name": stations[station_id]["name"],
                "predicted_peak": round(predicted_peak, 1),
                "confidence": 0.75,
                "timestamp": datetime.now().isoformat(),
                "method": "statistical_baseline"
            }
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì˜ˆì¸¡ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/monthly-contract/{station_id}")
async def get_monthly_contract_recommendation(station_id: str, year: int, month: int):
    """ì›”ë³„ ê³„ì•½ ì „ë ¥ ê¶Œê³ """
    try:
        stations = get_stations_with_cache()
        
        if station_id not in stations:
            raise HTTPException(status_code=404, detail=f"ì¶©ì „ì†Œ '{station_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        loader = ChargingDataLoader(station_id)
        patterns = loader.analyze_charging_patterns()
        
        if 'power_statistics' in patterns:
            stats = patterns['power_statistics']
            
            # ê³„ì ˆì„± ì¡°ì •
            seasonal_factors = {
                12: 1.20, 1: 1.20, 2: 1.15,
                3: 1.05, 4: 1.0, 5: 1.0,
                6: 1.10, 7: 1.15, 8: 1.10,
                9: 1.0, 10: 1.05, 11: 1.10
            }
            
            seasonal_factor = seasonal_factors.get(month, 1.0)
            predicted_peak = stats['percentile_95'] * seasonal_factor
            predicted_peak = min(predicted_peak, 95.0)
            
            recommended_contract = max(
                int(predicted_peak * 1.15 / 10) * 10,
                int(stats['max'] * 1.10 / 10) * 10
            )
            
            return {
                "station_id": station_id,
                "station_name": stations[station_id]["name"],
                "year": year,
                "month": month,
                "predicted_peak_kw": round(predicted_peak, 1),
                "recommended_contract_kw": recommended_contract,
                "seasonal_factor": seasonal_factor,
                "historical_data": {
                    "max_power": round(stats['max'], 1),
                    "avg_power": round(stats['mean'], 1),
                    "sessions_analyzed": stats['count']
                },
                "timestamp": datetime.now().isoformat()
            }
        else:
            return {
                "station_id": station_id,
                "station_name": stations[station_id]["name"],
                "year": year,
                "month": month,
                "predicted_peak_kw": 80.0,
                "recommended_contract_kw": 100,
                "note": "ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë³´ìˆ˜ì  ì¶”ì •"
            }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì›”ë³„ ê³„ì•½ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/station-analysis/{station_id}")
async def get_station_detailed_analysis(station_id: str):
    """ì¶©ì „ì†Œ ìƒì„¸ ë¶„ì„"""
    try:
        stations = get_stations_with_cache()
        
        if station_id not in stations:
            raise HTTPException(status_code=404, detail=f"ì¶©ì „ì†Œ '{station_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        loader = ChargingDataLoader(station_id)
        
        summary = loader.get_data_summary()
        patterns = loader.analyze_charging_patterns()
        realtime_status = loader.load_realtime_status()
        external_factors = loader.load_external_factors()
        
        # ì„±ëŠ¥ ë¶„ì„
        performance_analysis = {}
        charts_data = {}
        
        if 'power_statistics' in patterns:
            stats = patterns['power_statistics']
            avg_power = stats['mean']
            max_power = stats['max']
            
            utilization_rate = (avg_power / 100) * 100
            
            performance_analysis = {
                "utilization_rate": round(utilization_rate, 1),
                "peak_utilization": round((max_power / 100) * 100, 1),
                "average_session_power": round(avg_power, 1),
                "maximum_recorded_power": round(max_power, 1),
                "efficiency_grade": "A" if utilization_rate > 50 else "B" if utilization_rate > 30 else "C"
            }
            
            # ì°¨íŠ¸ ë°ì´í„° ì¤€ë¹„
            hourly_patterns = patterns.get('hourly_patterns', {})
            hourly_pattern = [
                hourly_patterns.get(str(h), {}).get('avg_power', 0) for h in range(24)
            ]
            
            charts_data = {
                "hourly_pattern": hourly_pattern,
                "monthly_predictions": {
                    "data": [round(stats['percentile_95'] * factor, 1) 
                            for factor in [1.20, 1.15, 1.05, 1.0, 1.0, 1.10, 1.15, 1.10, 1.0, 1.05, 1.10, 1.20]],
                    "labels": ["1ì›”", "2ì›”", "3ì›”", "4ì›”", "5ì›”", "6ì›”", "7ì›”", "8ì›”", "9ì›”", "10ì›”", "11ì›”", "12ì›”"]
                }
            }
        
        return {
            "station_id": station_id,
            "timestamp": datetime.now().isoformat(),
            "station_info": stations[station_id],
            "summary": summary,
            "patterns": patterns,
            "performance_analysis": performance_analysis,
            "charts_data": charts_data,
            "realtime_status": realtime_status,
            "external_factors": external_factors
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìƒì„¸ ë¶„ì„ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# === ê´€ë¦¬ API ===
@app.post("/api/admin/refresh-cache")
async def refresh_cache():
    """ìºì‹œ ìƒˆë¡œê³ ì¹¨"""
    try:
        invalidate_cache()
        stations = get_stations_with_cache()
        
        return {
            "message": "ìºì‹œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒˆë¡œê³ ì¹¨ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "stations_loaded": len(stations),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ìºì‹œ ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# === ì˜¤ë¥˜ ì²˜ë¦¬ ===
@app.exception_handler(404)
async def not_found_handler(request: Request, exc):
    return JSONResponse(
        status_code=404,
        content={
            "error": "Not Found",
            "message": "ìš”ì²­í•œ ë¦¬ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "help": {
                "available_endpoints": [
                    "/station-selector",
                    "/dashboard/{station_id}",
                    "/api/stations",
                    "/predict/{station_id}",
                    "/api/docs"
                ],
                "note": "ëª¨ë“  ì¶©ì „ì†Œ ì •ë³´ëŠ” CSV ë°ì´í„°ì—ì„œ ë™ì ìœ¼ë¡œ ë¡œë“œë©ë‹ˆë‹¤."
            }
        }
    )


if __name__ == "__main__":
    config = ConfigManager().config
    
    print("=" * 60)
    print("âš¡ 100kW ê¸‰ì†ì¶©ì „ì†Œ ì „ë ¥ ì˜ˆì¸¡ ì‹œìŠ¤í…œ (CSV ê¸°ë°˜)")
    print("=" * 60)
    print(f"ğŸŒ ì„œë²„ ì£¼ì†Œ: http://{config.api_host}:{config.api_port}")
    print(f"ğŸ¢ ì¶©ì „ì†Œ ì„ íƒ: http://{config.api_host}:{config.api_port}/station-selector")
    print(f"ğŸ“Š API ë¬¸ì„œ: http://{config.api_host}:{config.api_port}/api/docs")
    print(f"ğŸ’¾ CSV ê¸°ë°˜ ë™ì  ë¡œë”©")
    print("=" * 60)
    
    uvicorn.run(
        "main:app",
        host=config.api_host,
        port=config.api_port,
        workers=config.api_workers,
        reload=True,
        log_level="info"
    )