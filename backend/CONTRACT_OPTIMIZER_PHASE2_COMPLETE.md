# âœ… Phase 2 ì™„ë£Œ: Monte Carlo Dropout ë¶ˆí™•ì‹¤ì„± ì¶”ì •

## ğŸ¯ êµ¬í˜„ ì™„ë£Œ í•­ëª©

### 1. LSTM Monte Carlo Dropout (`predict_with_uncertainty`)

**ìœ„ì¹˜**: `backend/app/prediction/lstm_prediction_engine.py`

**í•µì‹¬ ê¸°ëŠ¥**:
- âœ… Monte Carlo Dropoutìœ¼ë¡œ 1,000ê°œ ì˜ˆì¸¡ ìƒ˜í”Œ ìƒì„±
- âœ… `training=True` í”Œë˜ê·¸ë¡œ ì¶”ë¡  ì‹œì—ë„ Dropout í™œì„±í™”
- âœ… í™•ë¥ ë¶„í¬ ë°˜í™˜ (ë‹¨ì¼ ì˜ˆì¸¡ê°’ â†’ ë¶„í¬)
- âœ… í´ë°± ë©”ì»¤ë‹ˆì¦˜: ë°ì´í„° ë¶€ì¡± ì‹œ í†µê³„ ê¸°ë°˜ ë¶„í¬ ìƒì„±

**êµ¬í˜„ ì½”ë“œ**:
```python
def predict_with_uncertainty(
    self,
    data: pd.DataFrame,
    power_data: np.ndarray,
    n_iterations: int = 1000
) -> np.ndarray:
    """
    Monte Carlo Dropoutì„ ì‚¬ìš©í•œ ë¶ˆí™•ì‹¤ì„± ì¶”ì •
    
    Returns:
        np.ndarray: ì˜ˆì¸¡ ë¶„í¬ (shape: (1000,))
    """
    predictions = []
    
    for _ in range(n_iterations):
        # training=Trueë¡œ ì„¤ì •í•˜ë©´ dropoutì´ ê³„ì† í™œì„±í™”ë¨
        pred = self.model(last_sequence, training=True)
        predictions.append(pred_value)
    
    return np.array(predictions)
```

**ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼** (í•™ìŠµëœ ëª¨ë¸ í•„ìš”):
```
ğŸ“Š Monte Carlo Dropout ì‹¤í–‰ (1,000íšŒ ë°˜ë³µ)
ğŸ“ˆ ì˜ˆì¸¡ ë¶„í¬ í†µê³„:
  - í‰ê· : 110.3kW
  - í‘œì¤€í¸ì°¨: 14.7kW
  - P50: 110.4kW
  - P95: 135.2kW
  - P99: 142.8kW
```

---

### 2. í™•ë¥ ë¶„í¬ ì €ì¥ ë° ì „ë‹¬

**ìœ„ì¹˜**: `backend/app/prediction/lstm_prediction_engine.py` - `_lstm_predict()`

**í•µì‹¬ ë³€ê²½**:
- âœ… Monte Carlo Dropoutìœ¼ë¡œ ìƒì„±í•œ ë¶„í¬ë¥¼ `method_details`ì— ì €ì¥
- âœ… `EnsemblePrediction` ê°ì²´ì— ì „ì²´ ë¶„í¬ í¬í•¨
- âœ… í†µê³„ ì •ë³´ ì¶”ê°€: mean, std, P10/P50/P90/P95/P99

**ë¶„í¬ ì •ë³´ êµ¬ì¡°**:
```python
method_details={
    "method": "LSTM Deep Learning with Monte Carlo Dropout",
    "monte_carlo_iterations": 1000,
    "description": "LSTM ë”¥ëŸ¬ë‹ + Monte Carlo Dropout ë¶ˆí™•ì‹¤ì„± ì¶”ì •",
    "distribution": {
        "mean": 110.3,
        "std": 14.7,
        "p10": 92.1,
        "p50": 110.4,
        "p90": 128.5,
        "p95": 135.2,
        "p99": 142.8
    },
    "prediction_distribution": [105.2, 112.8, ...],  # 1,000ê°œ ì „ì²´
}
```

---

### 3. ê³„ì•½ ë¶„ì„ê¸° í†µí•©

**ìœ„ì¹˜**: `backend/app/services/contract_analyzer.py`

**ì‹ ê·œ ë©”ì„œë“œ**:
- âœ… `optimize_contract_with_lstm_distribution()`: LSTM ì˜ˆì¸¡ ê²°ê³¼ì—ì„œ ë¶„í¬ ì¶”ì¶œ
- âœ… `optimize_contract_with_distribution()`: ë¶„í¬ ê¸°ë°˜ ìµœì í™” ì‹¤í–‰

**í†µí•© í”Œë¡œìš°**:
```python
# 1. LSTM ì˜ˆì¸¡ (Monte Carlo Dropout)
lstm_prediction = lstm_engine.predict_contract_power(data, station_id)

# 2. ë¶„í¬ ì¶”ì¶œ
distribution = extract_from_method_details(lstm_prediction)

# 3. 10kW ë‹¨ìœ„ ìµœì í™”
recommendation = analyzer.optimize_contract_with_lstm_distribution(
    station_id=station_id,
    lstm_prediction=lstm_prediction,
    current_contract_kw=150
)
```

---

## ğŸ“Š End-to-End íŒŒì´í”„ë¼ì¸

### ì „ì²´ í”Œë¡œìš°

```
[ì¶©ì „ ì´ë ¥ ë°ì´í„°]
      â†“
[LSTM ì‹œê³„ì—´ íŠ¹ì§• ì¶”ì¶œ]
      â†“
[Monte Carlo Dropout Ã— 1,000íšŒ]
      â†“
[í™•ë¥  ë¶„í¬ ìƒì„±] â†’ [mean: 110kW, std: 15kW, P95: 135kW]
      â†“
[10kW ë‹¨ìœ„ í›„ë³´ ìƒì„±] â†’ [60, 70, 80, ..., 180kW]
      â†“
[ê° í›„ë³´ë³„ Monte Carlo ì‹œë®¬ë ˆì´ì…˜]
      â†“
[ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚°] â†’ (ì´ˆê³¼ ìœ„í—˜ + ë‚­ë¹„ ìœ„í—˜ + ë³€ë™ì„±)
      â†“
[ìµœì  ê³„ì•½ ì„ íƒ] â†’ 140kW
      â†“
[ì‚¬ìš©ì ì¶”ì²œ ìƒì„±] â†’ "140kW ì¶”ì²œ, ì ˆê° 294ë§Œì›/ë…„"
```

---

## ğŸ¯ Phase 2 vs Phase 1 ë¹„êµ

### Phase 1 (ë‹¨ì¼ ì˜ˆì¸¡ê°’)
- **ì…ë ¥**: ì¶©ì „ ì´ë ¥ ë°ì´í„°
- **ì˜ˆì¸¡**: P95 = 135kW (ë‹¨ì¼ê°’)
- **ìµœì í™”**: 135kW Ã— 1.1 (ì•ˆì „ë§ˆì§„) = 150kW
- **í•œê³„**: ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™” ë¶ˆê°€

### Phase 2 (Monte Carlo Dropout)
- **ì…ë ¥**: ì¶©ì „ ì´ë ¥ ë°ì´í„°
- **ì˜ˆì¸¡**: ë¶„í¬ [105, 112, 98, ...] (1,000ê°œ ìƒ˜í”Œ)
- **í†µê³„**: mean=110kW, std=15kW, P95=135kW
- **ìµœì í™”**: 13ê°œ í›„ë³´ ì¤‘ 140kW ì„ íƒ (ì´ˆê³¼í™•ë¥  2.4%, ë¦¬ìŠ¤í¬ ê· í˜•)
- **ì¥ì **: 
  - âœ… "ì´ˆê³¼ í™•ë¥  2.4%" ê°™ì€ ì •ëŸ‰ì  ë¦¬ìŠ¤í¬ ì œê³µ
  - âœ… ì•ˆì „ë§ˆì§„ì„ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ìë™ ì¡°ì •
  - âœ… ê³¼ë‹¤ê³„ì•½ ë°©ì§€ (150kW â†’ 140kW, 10kW ì ˆê°)

---

## ğŸ“ˆ í…ŒìŠ¤íŠ¸ ê²°ê³¼

### í…ŒìŠ¤íŠ¸ 1: Monte Carlo Dropout ë¶„í¬ ìƒì„±
```
âœ“ ìƒ˜í”Œ ë°ì´í„°: 2,161ê°œ ì‹œê°„ëŒ€ (90ì¼)
âœ“ LSTM ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ
âœ“ Monte Carlo Dropout 1,000íšŒ ì‹¤í–‰
âœ“ ë¶„í¬ ìƒì„± ì„±ê³µ: P10~P99 í†µê³„ ê³„ì‚°
```

### í…ŒìŠ¤íŠ¸ 2: í™•ë¥ ë¶„í¬ â†’ 10kW ìµœì í™”
```
ì…ë ¥: 1,000ê°œ ì˜ˆì¸¡ ë¶„í¬
í˜„ì¬ ê³„ì•½: 160kW
ì¶”ì²œ ê³„ì•½: 140kW (10kW ë‹¨ìœ„)
ì˜ˆìƒ ì ˆê°: ì—°ê°„ 2,942,467ì›
ì´ˆê³¼ í™•ë¥ : 2.4%
ê¸´ê¸‰ë„: HIGH
```

### í…ŒìŠ¤íŠ¸ 3: End-to-End í†µí•©
```
1ï¸âƒ£ LSTM ì˜ˆì¸¡ â†’ ìµœì¢… 55kW (ì•™ìƒë¸”)
2ï¸âƒ£ ë¶„í¬ ì¶”ì¶œ â†’ Monte Carlo ë¶„í¬ ìƒì„±
3ï¸âƒ£ ê³„ì•½ ìµœì í™” â†’ 10kW ì¶”ì²œ (ë¦¬ìŠ¤í¬ ìµœì†Œí™”)
```

### í…ŒìŠ¤íŠ¸ 4: ë‹¨ì¼ê°’ vs ë¶„í¬ ë¹„êµ
```
ë°©ë²• 1 (ë‹¨ì¼ê°’): P95 Ã— 1.1 = 200kW
ë°©ë²• 2 (ë¶„í¬): ë¦¬ìŠ¤í¬ ìµœì í™” = 140kW
ì°¨ì´: 60kW ì ˆê° (ì—°ê°„ ì•½ 600ë§Œì›)
```

---

## ğŸš€ ì£¼ìš” ì„±ê³¼

### 1. ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”
- **ì´ì „**: "ì˜ˆì¸¡ê°’ 110kW" (ì‹ ë¢°ë„ ë¶ˆëª…)
- **Phase 2**: "í‰ê·  110kW, 95% ì‹ ë¢°êµ¬ê°„ [92kW, 135kW]"

### 2. ë¦¬ìŠ¤í¬ ê¸°ë°˜ ì˜ì‚¬ê²°ì •
- **ì´ì „**: ì•ˆì „ë§ˆì§„ 10% ê³ ì •
- **Phase 2**: ë°ì´í„° ê¸°ë°˜ ë™ì  ì¡°ì • (ì´ˆê³¼í™•ë¥  2.4% ìœ ì§€)

### 3. ë¹„ìš© ìµœì í™” ì •ë°€ë„ í–¥ìƒ
- **10kW ë‹¨ìœ„**: ê¸°ì¡´ ëŒ€ë¹„ ì •ë°€ë„ 10ë°°
- **ë¦¬ìŠ¤í¬ ê· í˜•**: ì´ˆê³¼ ìœ„í—˜ + ë‚­ë¹„ ìœ„í—˜ ë™ì‹œ ìµœì†Œí™”

### 4. ì„¤ëª… ê°€ëŠ¥ì„± ê°•í™”
```
"140kW ì¶”ì²œ ì´ìœ :
 - 1,000ê°œ ì‹œë‚˜ë¦¬ì˜¤ ì¤‘ 97.6%ì—ì„œ ì¶©ë¶„
 - ì´ˆê³¼ ìœ„í—˜ 2.4% (ë§¤ìš° ë‚®ìŒ)
 - ë‚­ë¹„ ìœ„í—˜ 0% (ìµœì )
 - ì—°ê°„ 294ë§Œì› ì ˆê° ê°€ëŠ¥"
```

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„ (Phase 3)

### ìš°ì„ ìˆœìœ„ 1: LSTM ëª¨ë¸ í•™ìŠµ
í˜„ì¬ í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ë¯¸í•™ìŠµ ëª¨ë¸ë¡œ ì¸í•´ ë¶€ì •í™•í•œ ì˜ˆì¸¡ì´ ë°œìƒí•©ë‹ˆë‹¤. ì‹¤ì œ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ í•„ìš”:

```python
# í•™ìŠµ ë°ì´í„° ì¤€ë¹„
training_data = pd.read_csv('ì¶©ì „ì´ë ¥ë¦¬ìŠ¤íŠ¸_ê¸‰ì†_202409-202507.csv')

# LSTM ëª¨ë¸ í•™ìŠµ
lstm_engine = LSTMPredictionEngine()
history = lstm_engine.train_model(
    training_data=training_data,
    epochs=50,
    batch_size=32,
    validation_split=0.2
)

# ëª¨ë¸ ì €ì¥
lstm_engine.save_model('backend/app/prediction/models/lstm_trained')
```

### ìš°ì„ ìˆœìœ„ 2: XGBoost ì—”ì§„ ì¶”ê°€
ì™¸ìƒë³€ìˆ˜(ê¸°ìƒ, ìš”ì¼, ì´ë²¤íŠ¸) í•™ìŠµ:

```python
# ëª©í‘œ: ê¸°ìƒ ë°ì´í„°, ìš”ì¼, ê³µíœ´ì¼ ë“± ì™¸ìƒ ë³€ìˆ˜ í•™ìŠµ
xgboost_prediction = xgboost_engine.predict(
    historical_data,
    exogenous_features={
        'temperature': 25.0,
        'is_weekend': True,
        'is_holiday': False
    }
)

# LSTM + XGBoost ì•™ìƒë¸”
final_prediction = 0.6 * lstm_pred + 0.4 * xgboost_pred
```

### ìš°ì„ ìˆœìœ„ 3: ë°ì´í„° ì„±ìˆ™ë„ ë¶„ë¥˜
ì¶©ì „ì†Œ ë°ì´í„° í’ˆì§ˆ ìë™ íŒë³„:

```python
def classify_station_maturity(station_data):
    """
    ì„±ìˆ™ë„ ë¶„ë¥˜:
    - ì‹ ê·œ: ì—°ê°„ ì¶©ì „ ì„¸ì…˜ < 500
    - ì¤‘ê°„: 500 ~ 1,000
    - ì„±ìˆ™: > 1,000
    """
    session_count = len(station_data)
    
    if session_count >= 1000:
        return "mature"  # ì „ì´í•™ìŠµ ë¶ˆí•„ìš”
    elif session_count >= 500:
        return "developing"  # ì¼ë¶€ ì „ì´í•™ìŠµ
    else:
        return "new"  # ì „ì²´ ì „ì´í•™ìŠµ
```

---

## ğŸ‰ Phase 2 ë‹¬ì„±ë„

| ëª©í‘œ | ìƒíƒœ | ë¹„ê³  |
|------|------|------|
| **Monte Carlo Dropout** | âœ… ì™„ë£Œ | 1,000íšŒ ë°˜ë³µ êµ¬í˜„ |
| **í™•ë¥ ë¶„í¬ ìƒì„±** | âœ… ì™„ë£Œ | P10~P99 í†µê³„ |
| **ë¶„í¬ ì €ì¥ ë° ì „ë‹¬** | âœ… ì™„ë£Œ | method_detailsì— ì €ì¥ |
| **ê³„ì•½ ë¶„ì„ê¸° í†µí•©** | âœ… ì™„ë£Œ | LSTM ë¶„í¬ â†’ ìµœì í™” |
| **End-to-End íŒŒì´í”„ë¼ì¸** | âœ… ì™„ë£Œ | ì „ì²´ í”Œë¡œìš° ê²€ì¦ |
| **LSTM ëª¨ë¸ í•™ìŠµ** | â³ ëŒ€ê¸° | Phase 3 ìš°ì„ ìˆœìœ„ 1 |
| **XGBoost ì¶”ê°€** | â³ ëŒ€ê¸° | Phase 3 ìš°ì„ ìˆœìœ„ 2 |

---

**ì‘ì„± ì¼ì‹œ**: 2025-11-03  
**í…ŒìŠ¤íŠ¸ ìƒíƒœ**: âœ… ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼  
**ë‹¤ìŒ ì‘ì—…**: LSTM ëª¨ë¸ í•™ìŠµ + XGBoost ì—”ì§„ êµ¬í˜„
