"""
LSTM ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

ì‹¤ì œ ê¸‰ì†ì¶©ì „ ë°ì´í„°ë¡œ LSTM ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'app'))

import pandas as pd
import numpy as np
from datetime import datetime
import logging

from app.prediction.lstm_prediction_engine import LSTMPredictionEngine

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_charging_data(file_path: str) -> pd.DataFrame:
    """ì¶©ì „ ì´ë ¥ ë°ì´í„° ë¡œë“œ"""
    logger.info(f"ë°ì´í„° ë¡œë“œ ì¤‘: {file_path}")
    
    try:
        # UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ ì½ê¸°
        df = pd.read_csv(file_path, encoding='utf-8')
        logger.info(f"âœ“ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}ê°œ ë ˆì½”ë“œ")
        
        return df
    
    except Exception as e:
        logger.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise


def preprocess_for_training(df: pd.DataFrame) -> pd.DataFrame:
    """í•™ìŠµìš© ë°ì´í„° ì „ì²˜ë¦¬"""
    logger.info("ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")
    
    # 1. í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_cols = ['ì¶©ì „ì‹œì‘ì¼ì‹œ', 'ì¶©ì „ì¢…ë£Œì¼ì‹œ', 'ìˆœê°„ìµœê³ ì „ë ¥', 'ì¶©ì „ì†ŒID']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
    
    # 2. ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
    df['ì¶©ì „ì‹œì‘ì¼ì‹œ'] = pd.to_datetime(df['ì¶©ì „ì‹œì‘ì¼ì‹œ'], errors='coerce')
    df['ì¶©ì „ì¢…ë£Œì¼ì‹œ'] = pd.to_datetime(df['ì¶©ì „ì¢…ë£Œì¼ì‹œ'], errors='coerce')
    
    # 3. ê²°ì¸¡ê°’ ì œê±°
    df = df.dropna(subset=['ì¶©ì „ì‹œì‘ì¼ì‹œ', 'ìˆœê°„ìµœê³ ì „ë ¥'])
    logger.info(f"âœ“ ê²°ì¸¡ê°’ ì œê±° í›„: {len(df):,}ê°œ ë ˆì½”ë“œ")
    
    # 4. ìˆœê°„ìµœê³ ì „ë ¥ì„ ìˆ«ìë¡œ ë³€í™˜
    df['ìˆœê°„ìµœê³ ì „ë ¥'] = pd.to_numeric(df['ìˆœê°„ìµœê³ ì „ë ¥'], errors='coerce')
    df = df.dropna(subset=['ìˆœê°„ìµœê³ ì „ë ¥'])
    
    # 4-1. ì¶©ì „ëŸ‰ë„ ìˆ«ìë¡œ ë³€í™˜
    if 'ì¶©ì „ëŸ‰(kWh)' in df.columns:
        df['ì¶©ì „ëŸ‰(kWh)'] = pd.to_numeric(df['ì¶©ì „ëŸ‰(kWh)'], errors='coerce')
    
    # 5. ìˆœê°„ìµœê³ ì „ë ¥ ì´ìƒê°’ ì œê±°
    df = df[df['ìˆœê°„ìµœê³ ì „ë ¥'] > 0]
    df = df[df['ìˆœê°„ìµœê³ ì „ë ¥'] <= 200]  # ê¸‰ì†ì¶©ì „ê¸° ìµœëŒ€ 200kW
    logger.info(f"âœ“ ì´ìƒê°’ ì œê±° í›„: {len(df):,}ê°œ ë ˆì½”ë“œ")
    
    # 6. ë‚ ì§œ ë²”ìœ„ í™•ì¸
    date_min = df['ì¶©ì „ì‹œì‘ì¼ì‹œ'].min()
    date_max = df['ì¶©ì „ì‹œì‘ì¼ì‹œ'].max()
    logger.info(f"âœ“ ë°ì´í„° ê¸°ê°„: {date_min} ~ {date_max}")
    
    return df


def aggregate_hourly_data(df: pd.DataFrame, top_n_stations: int = 10) -> pd.DataFrame:
    """
    ì‹œê°„ ë‹¨ìœ„ë¡œ ë°ì´í„° ì§‘ê³„
    
    Args:
        df: ì›ë³¸ ì¶©ì „ ë°ì´í„°
        top_n_stations: ìƒìœ„ Nê°œ ì¶©ì „ì†Œë§Œ ì‚¬ìš© (í•™ìŠµ ì†ë„ í–¥ìƒ)
    """
    logger.info("ì‹œê°„ ë‹¨ìœ„ ì§‘ê³„ ì‹œì‘...")
    
    # 1. ì¶©ì „ëŸ‰ì´ ë§ì€ ìƒìœ„ ì¶©ì „ì†Œ ì„ íƒ
    station_usage = df.groupby('ì¶©ì „ì†ŒID')['ìˆœê°„ìµœê³ ì „ë ¥'].agg(['count', 'mean'])
    station_usage = station_usage.sort_values('count', ascending=False)
    top_stations = station_usage.head(top_n_stations).index.tolist()
    
    logger.info(f"âœ“ ìƒìœ„ {top_n_stations}ê°œ ì¶©ì „ì†Œ ì„ íƒ:")
    for i, station in enumerate(top_stations, 1):
        count = station_usage.loc[station, 'count']
        mean_power = station_usage.loc[station, 'mean']
        logger.info(f"  {i}. {station}: {count:,}íšŒ ì¶©ì „, í‰ê·  {mean_power:.1f}kW")
    
    # 2. ì„ íƒëœ ì¶©ì „ì†Œë§Œ í•„í„°ë§
    df_filtered = df[df['ì¶©ì „ì†ŒID'].isin(top_stations)].copy()
    logger.info(f"âœ“ í•„í„°ë§ í›„: {len(df_filtered):,}ê°œ ë ˆì½”ë“œ")
    
    # 3. ì‹œê°„ ë‹¨ìœ„ë¡œ ì§‘ê³„ (ê° ì‹œê°„ëŒ€ì˜ ìµœëŒ€ ì „ë ¥ ì‚¬ìš©)
    df_filtered['hour'] = df_filtered['ì¶©ì „ì‹œì‘ì¼ì‹œ'].dt.floor('H')
    
    hourly_data = df_filtered.groupby('hour').agg({
        'ìˆœê°„ìµœê³ ì „ë ¥': ['max', 'mean', 'count'],
        'ì¶©ì „ëŸ‰(kWh)': 'sum'
    }).reset_index()
    
    # ì»¬ëŸ¼ëª… ë‹¨ìˆœí™”
    hourly_data.columns = ['timestamp', 'ìˆœê°„ìµœê³ ì „ë ¥', 'mean_power', 'session_count', 'ì¶©ì „ëŸ‰(kWh)']
    
    # 4. ì‹œê°„ ì¸ë±ìŠ¤ ì„¤ì •
    hourly_data = hourly_data.set_index('timestamp')
    hourly_data = hourly_data.sort_index()
    
    logger.info(f"âœ“ ì‹œê°„ ë‹¨ìœ„ ì§‘ê³„ ì™„ë£Œ: {len(hourly_data):,}ê°œ ì‹œê°„ëŒ€")
    logger.info(f"  - í‰ê·  ì „ë ¥: {hourly_data['ìˆœê°„ìµœê³ ì „ë ¥'].mean():.1f}kW")
    logger.info(f"  - ìµœëŒ€ ì „ë ¥: {hourly_data['ìˆœê°„ìµœê³ ì „ë ¥'].max():.1f}kW")
    logger.info(f"  - í‘œì¤€í¸ì°¨: {hourly_data['ìˆœê°„ìµœê³ ì „ë ¥'].std():.1f}kW")
    
    return hourly_data


def split_train_val(data: pd.DataFrame, val_ratio: float = 0.2):
    """í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• """
    split_idx = int(len(data) * (1 - val_ratio))
    
    train_data = data.iloc[:split_idx]
    val_data = data.iloc[split_idx:]
    
    logger.info(f"âœ“ ë°ì´í„° ë¶„í• :")
    logger.info(f"  - í•™ìŠµ: {len(train_data):,}ê°œ ({len(train_data)/len(data)*100:.1f}%)")
    logger.info(f"  - ê²€ì¦: {len(val_data):,}ê°œ ({len(val_data)/len(data)*100:.1f}%)")
    
    return train_data, val_data


def train_lstm_model(
    data_path: str,
    model_save_path: str = 'app/prediction/models/lstm_trained',
    top_n_stations: int = 10,
    epochs: int = 50,
    batch_size: int = 32
):
    """
    LSTM ëª¨ë¸ í•™ìŠµ ë©”ì¸ í•¨ìˆ˜
    
    Args:
        data_path: ì¶©ì „ ë°ì´í„° CSV ê²½ë¡œ
        model_save_path: í•™ìŠµëœ ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        top_n_stations: í•™ìŠµì— ì‚¬ìš©í•  ìƒìœ„ ì¶©ì „ì†Œ ìˆ˜
        epochs: í•™ìŠµ ì—í¬í¬
        batch_size: ë°°ì¹˜ í¬ê¸°
    """
    logger.info("=" * 80)
    logger.info("LSTM ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    logger.info("=" * 80)
    
    # 1. ë°ì´í„° ë¡œë“œ
    df = load_charging_data(data_path)
    
    # 2. ì „ì²˜ë¦¬
    df = preprocess_for_training(df)
    
    # 3. ì‹œê°„ ë‹¨ìœ„ ì§‘ê³„
    hourly_data = aggregate_hourly_data(df, top_n_stations=top_n_stations)
    
    # 4. í•™ìŠµ/ê²€ì¦ ë¶„í• 
    train_data, val_data = split_train_val(hourly_data, val_ratio=0.2)
    
    # 5. LSTM ì—”ì§„ ì´ˆê¸°í™”
    logger.info("\n" + "=" * 80)
    logger.info("LSTM ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    logger.info("=" * 80)
    
    lstm_engine = LSTMPredictionEngine()
    
    # 6. ëª¨ë¸ í•™ìŠµ
    history = lstm_engine.train_model(
        training_data=train_data,
        epochs=epochs,
        batch_size=batch_size,
        validation_split=0.2
    )
    
    # 7. í•™ìŠµ ê²°ê³¼ ì¶œë ¥
    if history.get('success'):
        logger.info("\n" + "=" * 80)
        logger.info("âœ… í•™ìŠµ ì™„ë£Œ!")
        logger.info("=" * 80)
        logger.info(f"ìµœì¢… Loss: {history['final_loss']:.4f}")
        logger.info(f"ê²€ì¦ Loss: {history['final_val_loss']:.4f}")
        logger.info(f"MAE: {history['final_mae']:.4f}")
        logger.info(f"í•™ìŠµ ì—í¬í¬: {history['epochs_trained']}")
        logger.info(f"í•™ìŠµ ìƒ˜í”Œ ìˆ˜: {history['training_samples']}")
        
        # 8. ëª¨ë¸ ì €ì¥
        logger.info(f"\nëª¨ë¸ ì €ì¥ ì¤‘: {model_save_path}")
        lstm_engine.save_model(model_save_path)
        logger.info("âœ“ ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
        
        # 9. ê²€ì¦ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
        logger.info("\n" + "=" * 80)
        logger.info("ê²€ì¦ ë°ì´í„° í…ŒìŠ¤íŠ¸")
        logger.info("=" * 80)
        
        test_prediction = lstm_engine.predict_contract_power(
            data=val_data,
            station_id="TEST_VALIDATION",
            charger_type="ê¸‰ì†ì¶©ì „ê¸° (DC)"
        )
        
        logger.info(f"ì˜ˆì¸¡ ê²°ê³¼: {test_prediction.final_prediction}kW")
        logger.info(f"ì‹¤ì œ P95: {val_data['ìˆœê°„ìµœê³ ì „ë ¥'].quantile(0.95):.1f}kW")
        logger.info(f"ì•™ìƒë¸” ë°©ë²•: {test_prediction.ensemble_method}")
        logger.info(f"ë¶ˆí™•ì‹¤ì„±: Â±{test_prediction.uncertainty:.1f}kW")
        
        return lstm_engine, history
    
    else:
        logger.error(f"\nâŒ í•™ìŠµ ì‹¤íŒ¨: {history.get('error')}")
        return None, history


if __name__ == "__main__":
    # ë°ì´í„° ê²½ë¡œ
    DATA_PATH = r'C:\Users\fordr\Desktop\power-demand-prediciton-platform\data\raw\ì¶©ì „ì´ë ¥ë¦¬ìŠ¤íŠ¸_ê¸‰ì†_202409-202507.csv'
    
    # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
    MODEL_SAVE_PATH = 'app/prediction/models/lstm_trained'
    
    # í•™ìŠµ ì‹¤í–‰
    try:
        lstm_engine, history = train_lstm_model(
            data_path=DATA_PATH,
            model_save_path=MODEL_SAVE_PATH,
            top_n_stations=10,  # ìƒìœ„ 10ê°œ ì¶©ì „ì†Œ
            epochs=50,          # 50 ì—í¬í¬
            batch_size=32       # ë°°ì¹˜ í¬ê¸° 32
        )
        
        if lstm_engine:
            print("\n" + "=" * 80)
            print("ğŸ‰ LSTM ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ!")
            print("=" * 80)
            print(f"ëª¨ë¸ ê²½ë¡œ: {MODEL_SAVE_PATH}")
            print("\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
            print("```python")
            print("from app.prediction.lstm_prediction_engine import LSTMPredictionEngine")
            print(f"lstm_engine = LSTMPredictionEngine(model_path='{MODEL_SAVE_PATH}')")
            print("prediction = lstm_engine.predict_contract_power(data, station_id)")
            print("```")
    
    except Exception as e:
        logger.error(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        print(f"\nâŒ í•™ìŠµ ì‹¤íŒ¨: {e}")
